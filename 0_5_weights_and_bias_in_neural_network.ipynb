{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsarfraz/Tiny-Machine-Learning/blob/main/0_5_weights_and_bias_in_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook I will be revisitng the single-layer neural network that I created in notebook 0.3\n",
        "\n",
        "I will now add a additional layer to this neural network (making it a two-layered network) and will be adding a additional neuron to the first layer."
      ],
      "metadata": {
        "id": "eSHF35MFLCx1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QCm3x_4F8bvg"
      },
      "outputs": [],
      "source": [
        "### IMPORTING LIBRARIES ###\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "### MAKING SURE THAT USER HAS TENSORFLOW 2 AND PYTHON 3 ###\n",
        "\n",
        "# This script requires TensorFlow 2 and Python 3.\n",
        "if tf.__version__.split('.')[0] != '2':\n",
        "    raise Exception((f\"The script is developed and tested for tensorflow 2. \"\n",
        "                     f\"Current version: {tf.__version__}\"))\n",
        "\n",
        "if sys.version_info.major < 3:\n",
        "    raise Exception((f\"The script is developed and tested for Python 3. \"\n",
        "                     f\"Current version: {sys.version_info.major}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Key Concepts\n",
        "\n",
        "Before I write the code of the single and double-layer neural networks I am going to define sone essential concepts/terms that will help in understanding how a neural net works.\n",
        "\n",
        "## Neurons\n",
        "\n",
        "Neurons are the basic units of a artificial neural network (ANN) or simulated neural network (SNN). Each neuron is connected to some/all of the neurons in the next layer. When inputs are transferred between neurons the weights are applied to the inputs along with the bias.\n",
        "\n",
        "## Weights\n",
        "\n",
        "Weights contol the signal (the connection strength) between two neurons. In other words, a weight decides how much influence the input would have on the neuron output.\n",
        "\n",
        "## Bias\n",
        "\n",
        "Biases are constant and always set to be 1 (this value can be changed). They are a additional input to the hidden and output layers but are not influenced by any layers behind them (they do not have any connections with the neurons in the previous layers). Biases are essentially constants associated with one neuron and their purpose is to ensure that when all the inputs, of the neuron, are zero that the neuron will still be activated.\n",
        "\n",
        "Biases are added to each individual neuron. I have included a illustration that shows how biases are added to each neuron in a 3-layered neural network:\n",
        "\n",
        "![illustration of how biases are added to each neuron in a neural net](images/0.5_bias_in_each_layer.jpg)\n",
        "\n",
        "## Linear Transformation\n",
        "\n",
        "Every neuron performs a linear transformation of its input using weights and biases. The linear transformation model is a equation of a straight line is slope-intercept form that looks like this:\n",
        "$$\n",
        "y= (weight*x) +bias\n",
        "$$\n",
        "\n",
        "It is important to ensure that a linear transformation is not the only thing that is used in each neuron because all layers in the neural network will behave in the same way since the composition of two linear functions is a linear function. A neural network will not be able to learn any complex task if linear transformations are only used in each neuron without anything else (such as activation functions).\n",
        "\n",
        "## Activation Functions\n",
        "\n",
        "**NOTE:** In this notebook, the neural networks that are created do not have activation functions which means that the linear transformation is only used in each neuron. I will be utlizing activation functions in future notebooks but wanted to define the concept here.\n",
        "\n",
        "Activation functions are a additional step to each layer and run after the linear transformation, of each neuron from the previous layer, occurs. An activation function decides whether a neuron should be activated (\"fired\"). In other words, deciding whether sending the neuron's input to the next layer of the neural network is important.\n",
        "\n",
        "There are many types of activation functions, some of them are:\n",
        "\n",
        "*  Binary Step Activation Functions\n",
        "*  Linear Activation Functions\n",
        "*  Sigmoid Activation Functions\n",
        "*  ReLU Activation Functions\n",
        "*  Softmax Activation Functions\n",
        "\n",
        "The image below illustrates how activation functions work. As you can see, the primary role of the activation function is to transform the summed weighted input from the neurons, in the previous layer, into a ouput value that can be fed into the next hidden layer or be used as final the neural networks final output.\n",
        "\n",
        "![illustration of activation functions](images/0.5_activation_function.jpg)\n"
      ],
      "metadata": {
        "id": "OroDzwqaJaRA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATGD5hNP0QIB"
      },
      "source": [
        "# Retraining the single layer network\n",
        "\n",
        "I am re-training the original single layer network that was created in notebook 0.3 and will display the ML model prediction when x =10. I will also display the learned weights of the single layer network.\n",
        "\n",
        "## Detailed Explanation of the Code  \n",
        "\n",
        "I have included a detailed explanation about the code used to build the neural net in [notebook 0.3](https://github.com/hsarfraz/Tiny-Machine-Learning/blob/main/0_3_Neural_Network_Basics.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLqOZPfC8gfb",
        "outputId": "cd25bc11-d959-479c-f8e7-7bd23762f306"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d6605923460>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "### defining my first layer ###\n",
        "# `.Dense` defines the layer type. A dense layer means that the neurons will get their source of input data from all the other neurons in the previous layer of the network\n",
        "my_layer = keras.layers.Dense(units=1, #`units=1` defines how many neurons will be included in the layer\n",
        "                              input_shape=[1] #`input_shape=[1]` has to be defined in the first layer. The input shape is 1 since the neural net is trained on single x's to predict single y's\n",
        "                              )\n",
        "\n",
        "### defining the model ###\n",
        "# `.Sequential` defines the neural network. A sequential neural network tells the neural net to operate from input to output, passing through each neural layers, one after the other\n",
        "model_1 = tf.keras.Sequential([my_layer])\n",
        "\n",
        "### compiling the model ###\n",
        "# Model compilation is performed after defining the neural net model and before model training starts. Model training cannot occur without model compilation\n",
        "model_1.compile(optimizer='sgd', #`optimizer='sgd'` is the stohastic gradient descent (sgd) optimizer which uses the gradient to descend down the loss curve and reach the minimum.\n",
        "                loss='mean_squared_error' #`loss='mean_squared_error'` a loss function from Tensorflow which computes the squared distance between the true and predicted inputs and calculates the mean of those values.\n",
        "                )\n",
        "\n",
        "### defining the exact inputs and outputs\n",
        "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
        "\n",
        "### model fitting ###\n",
        "# Model Fitting is the process of training the neural network to figure out the relationship between X and Y\n",
        "#`epoch=500` defines the amount of training rounds made for the neural metwork/model.\n",
        "model_1.fit(xs, ys, epochs=500, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing the model prediction at x=10 and the model weights"
      ],
      "metadata": {
        "id": "w4Nelx1oAdqj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtu5rJBA8o9M",
        "outputId": "946f1ed2-5d5b-4573-b9c5-ef9a963b3b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 366ms/step\n",
            "The model predicts that when x=10 the y output is: 18.98309898376465\n",
            "\n",
            "Printing the weights and biases of the only layer in the model\n",
            "[array([[1.9975504]], dtype=float32), array([-0.9924054], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"The model predicts that when x=10 the y output is: {model_1.predict([10.0])[0][0]}\")\n",
        "print()\n",
        "print('Printing the weights and biases of the only layer in the model')\n",
        "print(my_layer.get_weights())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing the model summary\n",
        "\n",
        "The model summary tells us the neural network type and the type of each layer"
      ],
      "metadata": {
        "id": "vRXnJhZyAoP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_1.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2v557E_qYKY",
        "outputId": "eaf44163-29f2-4f57-a2c2-a1574a0a43de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2 (8.00 Byte)\n",
            "Trainable params: 2 (8.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc18N_LA0QIE"
      },
      "source": [
        "# Training the 2-layer network and seeing its prediction and weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT2ajN1fvAzJ",
        "outputId": "72959859-2dde-4018-dc77-1a6b34362e48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d6606097130>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "my_layer_1 = keras.layers.Dense(units=2, input_shape=[1]) #the first layer\n",
        "my_layer_2 = keras.layers.Dense(units=1) #the second layer\n",
        "model_2 = tf.keras.Sequential([my_layer_1, my_layer_2]) #defining the model\n",
        "model_2.compile(optimizer='sgd', loss='mean_squared_error') #compiling the model\n",
        "\n",
        "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
        "\n",
        "model_2.fit(xs, ys, epochs=500, verbose=0) #model fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing the model prediction at x=10 and the model weights of each layer"
      ],
      "metadata": {
        "id": "VvRe0kckBAla"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caJ7xfgPvRnV",
        "outputId": "18a9c105-1432-4998-e7e4-48c83175d1d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 78ms/step\n",
            "The model predicts that when x=10 the y output is: 18.999996185302734\n",
            "\n",
            "Printing the weights and biases in the first layer\n",
            "[array([[-0.29593694, -1.430146  ]], dtype=float32), array([0.08875442, 0.5752448 ], dtype=float32)]\n",
            "\n",
            "Printing the weights and biases in the second layer\n",
            "[array([[-0.5179822],\n",
            "       [-1.2912734]], dtype=float32), array([-0.21122728], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "print(f\"The model predicts that when x=10 the y output is: {model_2.predict([10.0])[0][0]}\")\n",
        "print()\n",
        "print('Printing the weights and biases in the first layer')\n",
        "print(my_layer_1.get_weights())\n",
        "print()\n",
        "print('Printing the weights and biases in the second layer')\n",
        "print(my_layer_2.get_weights())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing the model summary"
      ],
      "metadata": {
        "id": "Czg3uIJzA7by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_2.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5LmXK5ouBx8",
        "outputId": "87a3f1bb-85dd-4ac5-ab6d-f3d31d9936d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 2)                 4         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7 (28.00 Byte)\n",
            "Trainable params: 7 (28.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwL3-Ujg0QIG"
      },
      "source": [
        "# Manually computing the output for the 2-layer network\n",
        "\n",
        "To better understand how the output is calculated in a two layered network I am manually calculating the ouput. Here is the formula (**Note:** all of the weights and biases are from layer 2):\n",
        "\n",
        "$$\n",
        "y = (w_1 * x_1) + (w_2 * x_2) + b\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snvWM5NRvgg9",
        "outputId": "dc820e23-ed28-46c3-e966-f045104ccf90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2.8706149980425835\n",
            "-13.72621500492096\n",
            "18.999996\n"
          ]
        }
      ],
      "source": [
        "value_to_predict = 10.0\n",
        "\n",
        "layer1_w1 = (my_layer_1.get_weights()[0][0][0])\n",
        "layer1_w2 = (my_layer_1.get_weights()[0][0][1])\n",
        "layer1_b1 = (my_layer_1.get_weights()[1][0])\n",
        "layer1_b2 = (my_layer_1.get_weights()[1][1])\n",
        "\n",
        "\n",
        "layer2_w1 = (my_layer_2.get_weights()[0][0])\n",
        "layer2_w2 = (my_layer_2.get_weights()[0][1])\n",
        "layer2_b = (my_layer_2.get_weights()[1][0])\n",
        "\n",
        "neuron1_output = (layer1_w1 * value_to_predict) + layer1_b1\n",
        "neuron2_output = (layer1_w2 * value_to_predict) + layer1_b2\n",
        "\n",
        "neuron3_output = (layer2_w1 * neuron1_output) + (layer2_w2 * neuron2_output) + layer2_b\n",
        "\n",
        "print(neuron1_output)\n",
        "print(neuron2_output)\n",
        "print(neuron3_output[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
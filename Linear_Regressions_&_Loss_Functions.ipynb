{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsarfraz/Tiny-Machine-Learning/blob/main/Linear_Regressions_%26_Loss_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Linear Regression** (discussing the slope-intercept form and loss function)\n",
        "\n",
        "#### > Linear Regression Overview\n",
        "\n",
        "A linear regression is a type of **machine learning algorithm**. A machine learning algorithm is a procedure that runs on datasets to identify patterns and rules in that dataset. Machine learning models are the output of the algorithm, they are used to run on datasets to make predictions on the data.\n",
        "\n",
        "Recap of important concepts discussed:\n",
        "\n",
        "Word | Definition\n",
        "-------------------|------------------\n",
        "**machine learning algorithm** | A procedure that runs on datasets to identify patterns and rules\n",
        "**machine learning model** | The output of the algorithm which is used to make new analysis/predictions on same dataset or predictions on similar datasets\n",
        "\n",
        "\n",
        "A **machine learning algorithm** learns from the data and makes sure that the model it produces can give the most accurate answers/predictions of the data. Machine learning algorithms fall into four main categories (supervised, unsuperviced, semi-supervised, and reinforcement learning). I will briefly talk about supervised and unsupervised learning and the algorithms that fall under these ML-algorithm categories.\n",
        "\n",
        "\n",
        "Machine Learning Algorithm Category | Algorithms\n",
        "-------------------|------------------\n",
        "**Supervised Learning Methods** | Regression (linear, logistic), Classification\n",
        "**Un-Supervised Learning Methods** | Clusturing, Unsupervised Anomaly Detection\n",
        "\n",
        "\n",
        "1. **Supervised Machine Learning**: Used to classify data (through label) and to make predictions\n",
        "\n",
        "  *   **Regression (linear, logistic)**: Used for predicting outcomes from continously changing data\n",
        "  *   **Classification**: Categorizes a given set of input data into classes based on one or more variables\n",
        "\n",
        "2. **Unsupervised Machine Learning**: Used to understand relationships between datasets and does not assign labels to the data\n",
        "\n",
        "  *    **Clustering**: Used to discover the underlying structure of the data. Data is gathered into groups/clusters instead of being labeled.\n",
        "  *    **Unsupervised Anomaly Detection**: Improves the quality of datasets by removing outliers. Unsupervised anomaly detection does not rely on labels to identify outliers and uses statistical/distance-related measures to identify outliers.\n",
        "\n",
        "---\n",
        "#### > The Slope-Intercept Form Formula\n",
        "\n",
        "\n",
        "---\n",
        "#### > The Loss Function Formula\n",
        "\n",
        "The loss function essentially measures how well your guess is. The loss function formula is listed below (I have defined some important variables in the formula below):\n",
        "\n",
        "\n",
        "\n",
        "*   **`i=0`** represents the index, in python a list index starts from zero\n",
        "*   **`n`** represents the total number of indexes that will occue\n",
        "*   **`y`** represents the actual y values that need to be matched\n",
        "*   **`y_i`** represents the predicted y values that we got from our loss function\n",
        "\n",
        "$$\n",
        "Loss = \\sqrt{ \\sum_{i=0}^{n}{(y-y_i)^2} }\n",
        "$$\n",
        "\n",
        "1.   The differences between the **actual y (`y`)** and **predicted y (`y_i`)** values are squared becuase some differences might be negative and positive so these values might cancel out when all the differences are added. By squaring the differences we ensure that all values will be positive thus taking into account all the differences.\n",
        "2.   Because the differences were squared we need to apply a square root to the sum of squared differences so we can obtain the actual loss function value\n",
        "\n",
        "\n",
        "\n",
        "Loss Function Output | Formula Accuracy\n",
        "-------------------|------------------\n",
        "When your loss is **minimized/small ⇓** | Your accuracy **increases ⇑**\n",
        "When your loss is **increases/large ⇑** | Your accuracy **decreases ⇓**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mcpp_mShubZr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwrR2q7tZKPi",
        "outputId": "01be14a1-14a3-496e-f463-04e69e36d9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "Real Y is [-3, -1, 1, 3, 5, 7]\n",
            "My Y is   [-4, -1, 2, 5, 8, 11]\n",
            "My loss is: 5.5677643628300215\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "# Edit these parameters to try different loss measurements. Rerun this cell when\n",
        "# done. Your Y will be calculated as Y=wX+b, so if w=3, and b=-1, then Y=3x-1.\n",
        "\n",
        "w = 3\n",
        "b = -1\n",
        "\n",
        "x = [-1, 0, 1, 2, 3, 4]\n",
        "y = [-3, -1, 1, 3, 5, 7]\n",
        "myY = []\n",
        "\n",
        "\n",
        "for thisX in x:\n",
        "  thisY = (w*thisX)+b\n",
        "  myY.append(thisY)\n",
        "  print(x.index(thisX))\n",
        "\n",
        "print(f\"Real Y is {str(y)}\")\n",
        "print(f\"My Y is   {str(myY)}\")\n",
        "\n",
        "# let's calculate the loss\n",
        "total_square_error = 0\n",
        "for i in range(0, len(y)):\n",
        "  square_error = (y[i] - myY[i]) ** 2\n",
        "  total_square_error += square_error\n",
        "\n",
        "print(f\"My loss is: {str(math.sqrt(total_square_error))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyA0mXMrs9K7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}